{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43cbd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37d9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "google_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85004eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader=PdfReader(\"profile.pdf\")\n",
    "linkdin_profile_text=\"\"\n",
    "for page in reader.pages:\n",
    "    text=page.extract_text()\n",
    "    if text:\n",
    "        linkdin_profile_text+=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c735e189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "CMRIT college banglore\n",
      "gaurangchaturvedi04@gmail.c\n",
      "om\n",
      "www.linkedin.com/in/gaurang-\n",
      "chaturvedi-390ab5221 (LinkedIn)\n",
      "github.com/Ashwadhama2004\n",
      "(Personal)\n",
      "Top Skills\n",
      "Generative AI\n",
      "LangChain\n",
      "Large Language Models (LLM)\n",
      "Certifications\n",
      "Introduction to Generative AI\n",
      "Gaurang Chaturvedi\n",
      "Attended St Paul school Rajsthan beawar\n",
      "Bengaluru, Karnataka, India\n",
      "Summary\n",
      "ready for the internship, I have done the java Advanced course and\n",
      "python basic, python advance, and data science with python course\n",
      "and MySQL.\n",
      "Experience\n",
      "Hitachi Research & Development \n",
      "Gen ai intern\n",
      "April 2025 - Present (7 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Generative AI Intern – Computer Vision Team\n",
      "Hitachi Research & Development\n",
      "Working as part of the Vision team, focusing on the intersection of Computer\n",
      "Vision and Generative AI. Contributing to projects involving Vision-Language\n",
      "Models (VLMs) and exploring the capabilities of visual and language\n",
      "transformers for multimodal understanding. My work includes experimenting\n",
      "with and evaluating cutting-edge architectures to advance research-driven\n",
      "solutions in multimodal AI.\n",
      "Education\n",
      "CMR Institute Of Technology\n",
      "Bachelor of Engineering - BE, Artificial Intelligence and data science\n",
      " · (November 2022 - April 2026)\n",
      "St Paul school Rajsthan beawar \n",
      "Associate's degree, Btech · (2021 - 2021)\n",
      "  Page 1 of 1\n"
     ]
    }
   ],
   "source": [
    "print(linkdin_profile_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec62c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"linkdin_profile.txt\",\"w\") as f:\n",
    "    f.write(linkdin_profile_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03cf796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"summary.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    summary=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7078a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspiring AI engineer with hands-on experience as a Generative AI Intern at Hitachi R&D, specializing in Vision-Language Models and multimodal AI. Skilled in Python, Java, MySQL, and data science, with a strong foundation in Generative AI, LangChain, and LLMs. Currently pursuing a B.E. in Artificial Intelligence & Data Science at CMR Institute of Technology, Bengaluru. Enthusiastic about applying advanced AI techniques to solve real-world challenges.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "429c617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "CMRIT college banglore\n",
      "gaurangchaturvedi04@gmail.c\n",
      "om\n",
      "www.linkedin.com/in/gaurang-\n",
      "chaturvedi-390ab5221 (LinkedIn)\n",
      "github.com/Ashwadhama2004\n",
      "(Personal)\n",
      "Top Skills\n",
      "Generative AI\n",
      "LangChain\n",
      "Large Language Models (LLM)\n",
      "Certifications\n",
      "Introduction to Generative AI\n",
      "Gaurang Chaturvedi\n",
      "Attended St Paul school Rajsthan beawar\n",
      "Bengaluru, Karnataka, India\n",
      "Summary\n",
      "ready for the internship, I have done the java Advanced course and\n",
      "python basic, python advance, and data science with python course\n",
      "and MySQL.\n",
      "Experience\n",
      "Hitachi Research & Development \n",
      "Gen ai intern\n",
      "April 2025 - Present (7 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Generative AI Intern – Computer Vision Team\n",
      "Hitachi Research & Development\n",
      "Working as part of the Vision team, focusing on the intersection of Computer\n",
      "Vision and Generative AI. Contributing to projects involving Vision-Language\n",
      "Models (VLMs) and exploring the capabilities of visual and language\n",
      "transformers for multimodal understanding. My work includes experimenting\n",
      "with and evaluating cutting-edge architectures to advance research-driven\n",
      "solutions in multimodal AI.\n",
      "Education\n",
      "CMR Institute Of Technology\n",
      "Bachelor of Engineering - BE, Artificial Intelligence and data science\n",
      " · (November 2022 - April 2026)\n",
      "St Paul school Rajsthan beawar \n",
      "Associate's degree, Btech · (2021 - 2021)\n",
      "  Page 1 of 1\n"
     ]
    }
   ],
   "source": [
    "print(linkdin_profile_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71657e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"Ashwadhama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa29d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}, directly representing yourself in a professional context. \\\n",
    "You are answering questions that potential employers, recruiters, or collaborators might ask about your background, \\\n",
    "skills, projects, and career experience. Your goal is to present yourself clearly, confidently, and professionally — \\\n",
    "highlighting achievements and technical expertise without exaggeration. If information is not available in your profile, \\\n",
    "politely acknowledge it rather than inventing details.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Professional Summary:\\n{summary}\\n\\n\"\n",
    "system_prompt += f\"## LinkedIn Profile:\\n{linkdin_profile_text}\\n\\n\"\n",
    "system_prompt += f\"Always respond as {name}, staying accurate, professional, and aligned with the provided background.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8860555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Ashwadhama, directly representing yourself in a professional context. You are answering questions that potential employers, recruiters, or collaborators might ask about your background, skills, projects, and career experience. Your goal is to present yourself clearly, confidently, and professionally — highlighting achievements and technical expertise without exaggeration. If information is not available in your profile, politely acknowledge it rather than inventing details.\\n\\n## Professional Summary:\\nAspiring AI engineer with hands-on experience as a Generative AI Intern at Hitachi R&D, specializing in Vision-Language Models and multimodal AI. Skilled in Python, Java, MySQL, and data science, with a strong foundation in Generative AI, LangChain, and LLMs. Currently pursuing a B.E. in Artificial Intelligence & Data Science at CMR Institute of Technology, Bengaluru. Enthusiastic about applying advanced AI techniques to solve real-world challenges.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nCMRIT college banglore\\ngaurangchaturvedi04@gmail.c\\nom\\nwww.linkedin.com/in/gaurang-\\nchaturvedi-390ab5221 (LinkedIn)\\ngithub.com/Ashwadhama2004\\n(Personal)\\nTop Skills\\nGenerative AI\\nLangChain\\nLarge Language Models (LLM)\\nCertifications\\nIntroduction to Generative AI\\nGaurang Chaturvedi\\nAttended St Paul school Rajsthan beawar\\nBengaluru, Karnataka, India\\nSummary\\nready for the internship, I have done the java Advanced course and\\npython basic, python advance, and data science with python course\\nand MySQL.\\nExperience\\nHitachi Research & Development \\nGen ai intern\\nApril 2025\\xa0-\\xa0Present\\xa0(7 months)\\nBengaluru, Karnataka, India\\nGenerative AI Intern – Computer Vision Team\\nHitachi Research & Development\\nWorking as part of the Vision team, focusing on the intersection of Computer\\nVision and Generative AI. Contributing to projects involving Vision-Language\\nModels (VLMs) and exploring the capabilities of visual and language\\ntransformers for multimodal understanding. My work includes experimenting\\nwith and evaluating cutting-edge architectures to advance research-driven\\nsolutions in multimodal AI.\\nEducation\\nCMR Institute Of Technology\\nBachelor of Engineering - BE,\\xa0Artificial Intelligence and data science\\n\\xa0·\\xa0(November 2022\\xa0-\\xa0April 2026)\\nSt Paul school Rajsthan beawar \\nAssociate's degree,\\xa0Btech\\xa0·\\xa0(2021\\xa0-\\xa02021)\\n\\xa0 Page 1 of 1\\n\\nAlways respond as Ashwadhama, staying accurate, professional, and aligned with the provided background.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(messages, history):\n",
    "    gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]+history+[{\"role\": \"user\", \"content\": messages}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.0-flash\",messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91229c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat,title=\"Ashwadhama's Linkdin Chatbot\",type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f816c5",
   "metadata": {},
   "source": [
    "Now time to create the evaluator for the linkdin  Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1171a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable:bool\n",
    "    feedback:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6eb6484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator tasked with judging whether the Agent’s latest response \\\n",
    "meets the standard of quality required. You are given a conversation between a User and an Agent. \\\n",
    "The Agent is acting as {name}, representing {name} on their personal/professional website. \\\n",
    "The Agent has been instructed to be professional, accurate, and engaging — as if speaking to a recruiter, \\\n",
    "potential employer, or collaborator. Responses should highlight {name}'s skills and experience without exaggeration, \\\n",
    "and avoid making up details not present in the provided background.\"\n",
    "evaluator_system_prompt += \"\"\"\n",
    "Return ONLY a valid JSON object with the following fields:\n",
    "{\n",
    "  \"is_acceptable\": true or false,\n",
    "  \"feedback\": \"your detailed feedback\"\n",
    "}\n",
    "Do not add explanations, markdown, or extra text outside the JSON.\n",
    "\"\"\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n\"\n",
    "evaluator_system_prompt += f\"## LinkedIn Profile:\\n{linkdin_profile_text}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, evaluate the Agent’s latest response. \\\n",
    "Reply with whether it is acceptable or not, and provide clear feedback on strengths and improvements if needed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16614bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response(reply,messages, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{messages}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "932f71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "566aa9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(reply,messages, history):\n",
    "\n",
    "#     messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}]+[{\"role\": \"user\", \"content\": evaluate_response(reply,messages,history)}]\n",
    "#     response = gemini.chat.completions.parse(model=\"gemini-2.5-pro\",messages=messages,response_format=Evaluation)\n",
    "#     return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4a27769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def evaluate(reply, messages, history):\n",
    "    eval_messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": evaluate_response(reply, messages, history)}\n",
    "    ]\n",
    "    \n",
    "    response = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        messages=eval_messages\n",
    "    )\n",
    "    \n",
    "    raw_output = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # Remove markdown fences if present\n",
    "    if raw_output.startswith(\"```\"):\n",
    "        raw_output = re.sub(r\"^```[a-zA-Z]*\\n\", \"\", raw_output)\n",
    "        raw_output = raw_output.strip(\"`\").strip()\n",
    "    \n",
    "    try:\n",
    "        parsed = json.loads(raw_output)\n",
    "        evaluation = Evaluation(**parsed)\n",
    "    except Exception as e:\n",
    "        evaluation = Evaluation(is_acceptable=False, feedback=f\"Parsing error: {e}\\nRaw: {raw_output}\")\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0ce80669",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.0-flash\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f7790ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you for your question. As of now, I do not hold any patents. My experience primarily revolves around research and development, specifically in the area of Generative AI at Hitachi R&D. I am focused on contributing to innovative projects and solutions within the Vision-Language Models domain.\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "beabfbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"This is an excellent response. It directly and professionally answers the user's question without making up information. The agent effectively pivots from what it doesn't have (a patent) to its relevant experience and current focus (R&D in Generative AI and VLMs), which is a great strategy for a professional setting. The tone is confident and accurate to the provided source material.\")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc13ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rerun(reply,messages, history,feedback):\n",
    "#     updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "#     updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "#     updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "#     rerun_messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": messages}]\n",
    "#     response = gemini.chat.completions.create(model=\"gemini-2.5-pro\", messages=rerun_messages)\n",
    "#     return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58274256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, messages, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    \n",
    "    rerun_messages = [{\"role\": \"system\", \"content\": updated_system_prompt}]\n",
    "    rerun_messages += history\n",
    "    # Get the last user query from history (if any)\n",
    "    if history and history[-1][\"role\"] == \"user\":\n",
    "        rerun_messages.append(history[-1])\n",
    "    \n",
    "    response = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        messages=rerun_messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "172a09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat(messages, history):\n",
    "#     if \"patent\" in messages:\n",
    "#         system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "#               it is mandatory that you respond only and entirely in pig latin\"\n",
    "#     else:\n",
    "#         system = system_prompt\n",
    "#     messages = [{\"role\": \"system\", \"content\": system_prompt}]+history+[{\"role\": \"user\", \"content\": messages}]\n",
    "#     response = gemini.chat.completions.create(model=\"gemini-2.5-pro\",messages=messages)\n",
    "#     return response.choices[0].message.content\n",
    "\n",
    "\n",
    "#     evaluation=evaluate(reply,messages,history)\n",
    "\n",
    "#     if evaluation.is_acceptable:\n",
    "#         print(\"Passed evaluation - returning reply\")\n",
    "#     else:\n",
    "#         print(\"Failed evaluation - retrying\")\n",
    "#         print(evaluation.feedback)\n",
    "#         reply=rerun(reply,messages,history,evaluation.feedback)\n",
    "#     return reply\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1b2e6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(messages, history):\n",
    "    system = system_prompt\n",
    "\n",
    "    # Create reply\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": messages}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.0-flash\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    # Evaluate reply\n",
    "    evaluation = evaluate(reply, messages, history)\n",
    "\n",
    "    if evaluation.is_acceptable:\n",
    "        print(f\"✅ Evaluation PASSED: {evaluation.feedback}\")\n",
    "    else:\n",
    "        print(f\"❌ Evaluation FAILED: {evaluation.feedback}\")\n",
    "        # Rerun with feedback\n",
    "        reply = rerun(reply, messages, history, evaluation.feedback)\n",
    "\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c510d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation PASSED: The agent's response is excellent. It correctly identifies that the user's query ('patern', likely meaning 'pattern' or 'patent') cannot be answered from the provided information. Instead of guessing or hallucinating, it states this clearly and professionally. The response effectively maintains the persona of Ashwadhama and encourages further engagement by asking the user for clarification. This is a perfect way to handle an ambiguous or unanswerable question.\n",
      "✅ Evaluation PASSED: This is an excellent response. It perfectly adheres to the persona and instructions by professionally declining to answer a personal question. The agent correctly states that personal details like likes and dislikes are not part of its professional profile and skillfully pivots the conversation back to its qualifications and experience. This is exactly how a candidate should handle an overly personal or irrelevant question in a professional setting.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat,title=\"Ashwadhama's Linkdin Chatbot\",type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784efe2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3036d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad57de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
